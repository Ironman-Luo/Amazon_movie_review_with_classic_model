{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as py\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# spacy for lemmatization\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from collections import Counter\n",
    "from gensim.test.utils import datapath\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from gensim.models import word2vec\n",
    "import re \n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from sklearn import svm\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltrainingSet = pd.read_pickle('result.pickle')\n",
    "trainingSet = fulltrainingSet\n",
    "trainingSet = trainingSet.set_index(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = pd.read_csv(\"test.csv\")['Id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = trainingSet.iloc[test_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductId                                             0005019281\n",
      "UserId                                             ADZPIG9QOCDG5\n",
      "Score                                                          4\n",
      "Time                                                  1203984000\n",
      "Summary                                good version of a classic\n",
      "Text           This is a charming version of the classic Dick...\n",
      "Helpfulness                                                    0\n",
      "reviews        good version of a classicThis is a charming ve...\n",
      "result                                                   4.40565\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(trainingSet.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = trainingSet[['UserId','ProductId']]\n",
    "#d = d.apply(LabelEncoder().fit_transform, axis = 0)\n",
    "#trainingSet['UserId'] = d['UserId']\n",
    "#trainingSet['ProductId'] = d['ProductId']\n",
    "#trainingSet = trainingSet[['ProductId','UserId','Score','Time','']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserId_group = trainingSet[['UserId','Score','result']]\n",
    "def show_all_result(x):\n",
    "    return [i for i in x]\n",
    "UserId_group = UserId_group.groupby(['UserId']).agg({'Score':lambda x: show_all_result(x), 'result': lambda x: show_all_result(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductId_group = trainingSet[['ProductId','Score','result']]\n",
    "def show_all_result(x):\n",
    "    return [i for i in x]\n",
    "ProductId_group = ProductId_group.groupby(['ProductId']).agg({'Score':lambda x: show_all_result(x), 'result': lambda x: show_all_result(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set_user = test_set.merge(UserId_group, on='UserId', how='left')\n",
    "#test_set_product = test_set.merge(ProductId_group, on='ProductId', how='left')\n",
    "train_set_user = fulltrainingSet.merge(UserId_group, on='UserId', how='left')\n",
    "train_set_product = fulltrainingSet.merge(ProductId_group, on='ProductId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set_user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_user = train_set_user[['UserId','Score_y','result_y','result_x']]\n",
    "sub_user = train_set_user[['Score_y','result_y']]\n",
    "sub_user = sub_user.apply(lambda x: np.array([i for i in x]), axis = 1)\n",
    "\n",
    "train_set_product = train_set_product[['UserId','Score_y','result_y','result_x']]\n",
    "sub_product = train_set_product[['Score_y','result_y']]\n",
    "sub_product = sub_product.apply(lambda x: np.array([i for i in x]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set_product = test_set_product[['HelpfulnessNumerator','HelpfulnessDenominator','ProductId','Score_y','result_y','result_x']]\n",
    "#sub_product = test_set_product[['Score_y','result_y']]\n",
    "#sub_product = sub_product.apply(lambda x: np.array([i for i in x]), axis = 1)\n",
    "#sub_help = test_set_product[['HelpfulnessNumerator','HelpfulnessDenominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lw/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def get_difference(lst):\n",
    "    lst = np.array(lst).transpose()\n",
    "    lst = lst[~np.isnan(lst).any(axis = 1)]\n",
    "    return np.mean(lst[:,0] - lst[:,1])\n",
    "sub_user = sub_user.apply(lambda x: get_difference(x))\n",
    "sub_product = sub_product.apply(lambda x: get_difference(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_user[sub_user != sub_user] = 0\n",
    "sub_product[sub_product != sub_product] = 0\n",
    "#result = s1['result_x'] + sub_s1 + sub_x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sub_user)\n",
    "print(sub_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Id   ProductId          UserId  Score        Time  \\\n",
      "0              0  0005019281   ADZPIG9QOCDG5    4.0  1203984000   \n",
      "1              1  0005019281  A35947ZP82G7JH    3.0  1388361600   \n",
      "2              2  0005019281  A3UORV8A9D5L2E    3.0  1388361600   \n",
      "3              3  0005019281  A1VKW06X1O2X7V    5.0  1202860800   \n",
      "4              4  0005019281  A3R27T4HADWFFJ    4.0  1387670400   \n",
      "...          ...         ...             ...    ...         ...   \n",
      "1697528  1697528  B00LT1JHLW   AV657BUYHHXZ2    NaN  1406073600   \n",
      "1697529  1697529  B00LT1JHLW  A17W587EH23J0Q    5.0  1405641600   \n",
      "1697530  1697530  B00LT1JHLW  A3DE438TF1A958    5.0  1405728000   \n",
      "1697531  1697531  B00LT1JHLW  A2RWCXDMANY0LW    5.0  1405987200   \n",
      "1697532  1697532  B00LT1JHLW  A3ROPC55BE2OM9    5.0  1405728000   \n",
      "\n",
      "                                                   Summary  \\\n",
      "0                                good version of a classic   \n",
      "1                                   Good but not as moving   \n",
      "2                    Winkler's Performance was ok at best!   \n",
      "3             It's an enjoyable twist on the classic story   \n",
      "4                                         Best Scrooge yet   \n",
      "...                                                    ...   \n",
      "1697528                      Way to Expensive!! WB = GREED   \n",
      "1697529  HOLY BAT-BOXSET, BATMAN... I never thought thi...   \n",
      "1697530  prayers have been answered because batman 60s ...   \n",
      "1697531                                        can't Wait!   \n",
      "1697532  The Price is Insane? People Really Need to Wak...   \n",
      "\n",
      "                                                      Text  Helpfulness  \\\n",
      "0        This is a charming version of the classic Dick...     0.000000   \n",
      "1        It was good but not as emotionally moving as t...     0.000000   \n",
      "2        Don't get me wrong, Winkler is a wonderful cha...     0.000000   \n",
      "3        Henry Winkler is very good in this twist on th...     0.000000   \n",
      "4        This is one of the best Scrooge movies out.  H...     0.000000   \n",
      "...                                                    ...          ...   \n",
      "1697528  wow $269.99 for the entire series on Blu Ray??...     0.071429   \n",
      "1697529  Finally, the holy grail of tv-on-dvd boxsets i...     0.666667   \n",
      "1697530  Could this be a true or I'm i dreaming batman ...     0.300000   \n",
      "1697531  I've been a fan of the series since I was a yo...     0.000000   \n",
      "1697532  People seriously need to wake up and realize t...     0.478261   \n",
      "\n",
      "                                                   reviews    result  \\\n",
      "0        good version of a classicThis is a charming ve...  4.405653   \n",
      "1        Good but not as movingIt was good but not as e...  4.243128   \n",
      "2        Winkler's Performance was ok at best!Don't get...  4.077961   \n",
      "3        It's an enjoyable twist on the classic storyHe...  4.322303   \n",
      "4        Best Scrooge yetThis is one of the best Scroog...  4.753433   \n",
      "...                                                    ...       ...   \n",
      "1697528  Way to Expensive!! WB = GREEDwow $269.99 for t...  3.810148   \n",
      "1697529  HOLY BAT-BOXSET, BATMAN... I never thought thi...  4.655209   \n",
      "1697530  prayers have been answered because batman 60s ...  4.833027   \n",
      "1697531  can't Wait!I've been a fan of the series since...  4.218191   \n",
      "1697532  The Price is Insane? People Really Need to Wak...  3.826205   \n",
      "\n",
      "          product      user  \n",
      "0        0.061717 -0.261170  \n",
      "1        0.061717 -0.511366  \n",
      "2        0.061717 -0.534398  \n",
      "3        0.061717 -0.167177  \n",
      "4        0.061717  0.046814  \n",
      "...           ...       ...  \n",
      "1697528  0.268836  0.138180  \n",
      "1697529  0.268836  0.226532  \n",
      "1697530  0.268836  0.429776  \n",
      "1697531  0.268836  0.513484  \n",
      "1697532  0.268836 -0.306211  \n",
      "\n",
      "[1697533 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "fulltrainingSet['product'] = sub_product\n",
    "fulltrainingSet['user'] = sub_user\n",
    "print(fulltrainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train= fulltrainingSet[['user','product','Helpfulness','result','Score','Time']].dropna()\n",
    "new_train_y = new_train['Score']\n",
    "new_train_x = new_train[['user','product','result','Helpfulness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.53686615 0.59025367 0.85141329 0.        ]\n",
      " [0.4958468  0.59025367 0.810782   0.        ]\n",
      " [0.49207064 0.59025367 0.76949027 0.        ]\n",
      " ...\n",
      " [0.6501463  0.63443386 0.95825672 0.0375    ]\n",
      " [0.66387019 0.63443386 0.80454784 0.        ]\n",
      " [0.52948172 0.63443386 0.70655128 0.05978261]]\n"
     ]
    }
   ],
   "source": [
    "new_train_x = new_train_x.to_numpy()\n",
    "scaling = MinMaxScaler(feature_range=(0,1)).fit(new_train_x)\n",
    "new_train_x = scaling.transform(new_train_x)\n",
    "print(new_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "new_train_y = np.array(new_train_y)\n",
    "print(new_train_y[new_train_y != new_train_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6476546204567327\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_train_x, new_train_y ,test_size=0.2)\n",
    "clf = LogisticRegression(C = 0.01,solver ='saga', max_iter = 1000)\n",
    "clf = clf.fit(new_train_x, new_train_y)\n",
    "print(clf.score(X_test,y_test))\n",
    "#clf = svm.SVC(kernel = \"linear\", gamma = 'auto')\n",
    "#clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = fulltrainingSet.iloc[test_index,:]\n",
    "test = test[['user','product','result','Helpfulness']].to_numpy()\n",
    "test = scaling.transform(test)\n",
    "test_result = clf.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8605636  4.23100599 4.02969948 ... 3.55579802 4.88084766 4.30182434]\n"
     ]
    }
   ],
   "source": [
    "test_1 = np.matmul(clf.predict_proba(test),np.array([1,2,3,4,5]))\n",
    "print(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1[test_1 > 5] = 5\n",
    "test_1[test_1 < 1] = 1\n",
    "test_1 = np.around(test_1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 4. 4. ... 4. 5. 4.]\n"
     ]
    }
   ],
   "source": [
    "print(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame({'Id':np.array(test_index),'Score':test_1})\n",
    "x.to_csv(\"result_10.csv\",index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
